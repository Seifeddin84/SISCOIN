{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZ/f3Zczp8D4fBa9aEppuF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seifeddin84/SISCOIN/blob/main/PINN_inverted_pendulum_for_human_quiet_balance_v03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFg5KXxl24tH",
        "outputId": "2107205b-7342-433c-91ba-2dadd20f411d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1930 WFDB records to process\n",
            "\n",
            "Initializing a PINN model for each file.\n",
            "\n",
            "==================================================\n",
            "Processing file 1/1930: BDS01002\n",
            "==================================================\n",
            "Loading WFDB record: /content/drive/MyDrive/human-balance-evaluation-database-1.0.0/BDS01002\n",
            "   Loaded 6000 data points\n",
            "   Subject: 67.9 kg, 0.85 m\n",
            "\n",
            "2. Training PINN model...\n",
            "Starting multi-phase training with 6000 data points...\n",
            "\n",
            "--- Phase 1/4 ---\n",
            "Data weight: 1.0, Physics weight: 0.1, Regularization: 0.01\n",
            "Epoch 0: Total Loss = 17.568775\n",
            "  Damping: 5.0010, Stiffness: 50.0499\n",
            "  Data: 17.567225, Physics: 0.015507, Reg: 0.000000\n",
            "Epoch 500: Total Loss = 0.056130\n",
            "  Damping: 8.0587, Stiffness: 91.1807\n",
            "  Data: 0.047247, Physics: 0.088830, Reg: 0.000000\n",
            "Epoch 1000: Total Loss = 0.051901\n",
            "  Damping: 13.5268, Stiffness: 176.1640\n",
            "  Data: 0.046019, Physics: 0.058826, Reg: 0.000000\n",
            "Epoch 1500: Total Loss = 0.046938\n",
            "  Damping: 19.4649, Stiffness: 340.5210\n",
            "  Data: 0.044974, Physics: 0.019634, Reg: 0.000000\n",
            "Epoch 2000: Total Loss = 0.044420\n",
            "  Damping: 19.4786, Stiffness: 488.7176\n",
            "  Data: 0.044192, Physics: 0.002289, Reg: 0.000000\n",
            "\n",
            "--- Phase 2/4 ---\n",
            "Data weight: 1.0, Physics weight: 0.3, Regularization: 0.05\n",
            "Epoch 2500: Total Loss = 0.042474\n",
            "  Damping: 19.4885, Stiffness: 496.0430\n",
            "  Data: 0.041917, Physics: 0.001858, Reg: 0.000000\n",
            "Epoch 3000: Total Loss = 0.040847\n",
            "  Damping: 19.5148, Stiffness: 494.3724\n",
            "  Data: 0.040257, Physics: 0.001966, Reg: 0.000000\n",
            "Epoch 3500: Total Loss = 0.037243\n",
            "  Damping: 19.5326, Stiffness: 496.1405\n",
            "  Data: 0.036686, Physics: 0.001857, Reg: 0.000000\n",
            "Epoch 4000: Total Loss = 0.033873\n",
            "  Damping: 19.5727, Stiffness: 498.7820\n",
            "  Data: 0.033351, Physics: 0.001742, Reg: 0.000000\n",
            "Epoch 4500: Total Loss = 0.032342\n",
            "  Damping: 19.6243, Stiffness: 498.3023\n",
            "  Data: 0.031811, Physics: 0.001773, Reg: 0.000000\n",
            "\n",
            "--- Phase 3/4 ---\n",
            "Data weight: 1.0, Physics weight: 0.7, Regularization: 0.1\n",
            "Epoch 5000: Total Loss = 0.031799\n",
            "  Damping: 19.6885, Stiffness: 498.5540\n",
            "  Data: 0.030568, Physics: 0.001759, Reg: 0.000000\n",
            "Epoch 5500: Total Loss = 0.030376\n",
            "  Damping: 19.8017, Stiffness: 497.6536\n",
            "  Data: 0.029097, Physics: 0.001827, Reg: 0.000000\n",
            "Epoch 6000: Total Loss = 0.028901\n",
            "  Damping: 19.4183, Stiffness: 497.8874\n",
            "  Data: 0.027634, Physics: 0.001810, Reg: 0.000000\n",
            "Epoch 6500: Total Loss = 0.028092\n",
            "  Damping: 19.3861, Stiffness: 497.9420\n",
            "  Data: 0.026875, Physics: 0.001740, Reg: 0.000000\n",
            "Epoch 7000: Total Loss = 0.027429\n",
            "  Damping: 19.2986, Stiffness: 499.6175\n",
            "  Data: 0.026213, Physics: 0.001737, Reg: 0.000000\n",
            "\n",
            "--- Phase 4/4 ---\n",
            "Data weight: 1.0, Physics weight: 1.0, Regularization: 0.2\n",
            "Epoch 7500: Total Loss = 0.027512\n",
            "  Damping: 19.2549, Stiffness: 499.3543\n",
            "  Data: 0.025743, Physics: 0.001769, Reg: 0.000000\n",
            "Epoch 8000: Total Loss = 0.027091\n",
            "  Damping: 19.0819, Stiffness: 498.5266\n",
            "  Data: 0.025310, Physics: 0.001781, Reg: 0.000000\n",
            "Epoch 8500: Total Loss = 0.026506\n",
            "  Damping: 18.6841, Stiffness: 498.6776\n",
            "  Data: 0.024729, Physics: 0.001777, Reg: 0.000000\n",
            "Epoch 9000: Total Loss = 0.025645\n",
            "  Damping: 18.2554, Stiffness: 499.1684\n",
            "  Data: 0.023887, Physics: 0.001758, Reg: 0.000000\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "SIMPLIFIED PHYSICS-INFORMED NEURAL NETWORKS FOR HUMAN BALANCE\n",
        "===========================================================================\n",
        "> A code designed and generated by google colab gemini + claude ai\n",
        "\n",
        "MODIFICATIONS TO FIX DAMPING ISSUE:\n",
        "1. Better initialization of damping and stiffness parameters\n",
        "2. Added parameter regularization loss\n",
        "3. Multi-phase training to gradually enforce physics\n",
        "4. Constraint damping to physiological range\n",
        "\n",
        "REQUIRED DATA: CSV files with columns Fx, Fy, Fz, Mx, My, Mz, COPx, COPy\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import wfdb\n",
        "import os\n",
        "import re\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: SIMPLE DATA LOADER (UNCHANGED)\n",
        "# ============================================================================\n",
        "\n",
        "def load_balance_data(file_path):\n",
        "    \"\"\"\n",
        "    Load balance data from WFDB files or CSV files.\n",
        "    Returns: time, COP data, and subject info\n",
        "    \"\"\"\n",
        "\n",
        "    # Try to load as WFDB first\n",
        "    if os.path.exists(file_path + '.dat') and os.path.exists(file_path + '.hea'):\n",
        "        print(f\"Loading WFDB record: {file_path}\")\n",
        "\n",
        "        # Load the WFDB record\n",
        "        record = wfdb.rdrecord(file_path)\n",
        "        data = pd.DataFrame(record.p_signal, columns=record.sig_name)\n",
        "        sample_rate = record.fs\n",
        "\n",
        "        # Extract subject info from .hea file, the mass m and hieght l\n",
        "        subject_info = {'weight': 75.0, 'height': 1.70}  # defaults\n",
        "\n",
        "        hea_file = file_path + '.hea'\n",
        "        if os.path.exists(hea_file):\n",
        "            with open(hea_file, 'r') as f:\n",
        "                content = f.read()\n",
        "                # Look for height and weight in comments\n",
        "                height_match = re.search(r'#Height:\\s*(\\d+\\.?\\d*)', content)\n",
        "                weight_match = re.search(r'#Weight:\\s*(\\d+\\.?\\d*)', content)\n",
        "\n",
        "                if height_match:\n",
        "                    subject_info['height'] = float(height_match.group(1)) * 0.55 / 100 # convert cm to m\n",
        "                if weight_match:\n",
        "                    subject_info['weight'] = float(weight_match.group(1))\n",
        "\n",
        "    else:\n",
        "        # Try to load as CSV\n",
        "        print(f\"Loading CSV file: {file_path}\")\n",
        "        data = pd.read_csv(file_path)\n",
        "        sample_rate = 50  # assume 100 Hz if not specified\n",
        "        subject_info = {'weight': 75.0, 'height': 1.70}  # defaults for CSV\n",
        "\n",
        "    # Make sure we have the required columns\n",
        "    required_cols = ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz', 'COPx', 'COPy']\n",
        "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
        "\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing columns: {missing_cols}\")\n",
        "\n",
        "    # Create time vector\n",
        "    time = np.linspace(0, len(data)/sample_rate, len(data))\n",
        "\n",
        "    # Extract COP data (what we want to predict)\n",
        "    cop_data = data[['COPx', 'COPy']].values\n",
        "\n",
        "    return time, cop_data, subject_info\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: MODIFIED NEURAL NETWORK WITH BETTER PARAMETER INITIALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "class SimpleBalancePINN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simplified neural network for balance prediction.\n",
        "    MODIFIED: Better parameter initialization and constraints\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Simple 3-layer network (unchanged)\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(1, 100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 2)\n",
        "        )\n",
        "\n",
        "        # Initialize weights for better training\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.xavier_normal_(layer.weight)\n",
        "\n",
        "        # MODIFIED: Better initialization for physics parameters\n",
        "        # Use log parameterization to ensure positivity and better gradients\n",
        "        self.log_damping = nn.Parameter(torch.tensor(np.log(5.0), dtype=torch.float32))  # exp(log(5)) = 5\n",
        "        self.log_stiffness = nn.Parameter(torch.tensor(np.log(50.0), dtype=torch.float32))  # exp(log(50)) = 50\n",
        "\n",
        "    @property\n",
        "    def damping(self):\n",
        "        \"\"\"Always positive damping via exponential\"\"\"\n",
        "        return torch.exp(self.log_damping)\n",
        "\n",
        "    @property\n",
        "    def stiffness(self):\n",
        "        \"\"\"Always positive stiffness via exponential\"\"\"\n",
        "        return torch.exp(self.log_stiffness)\n",
        "\n",
        "    def forward(self, t):\n",
        "        \"\"\"Given time t, predict COP position\"\"\"\n",
        "        return self.layers(t)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: MODIFIED PHYSICS EQUATIONS WITH REGULARIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def physics_loss(model, time_points, mass, height):\n",
        "    \"\"\"\n",
        "    Calculate how well the model follows physics laws.\n",
        "    MODIFIED: Uses the new property-based parameters\n",
        "    \"\"\"\n",
        "\n",
        "    # Enable gradients for computing derivatives\n",
        "    time_points.requires_grad_(True)\n",
        "\n",
        "    # Get model predictions\n",
        "    position = model(time_points)\n",
        "\n",
        "    # Calculate velocity (first derivative)\n",
        "    velocity = torch.autograd.grad(position.sum(), time_points, create_graph=True)[0]\n",
        "\n",
        "    # Calculate acceleration (second derivative)\n",
        "    acceleration = torch.autograd.grad(velocity.sum(), time_points, create_graph=True)[0]\n",
        "\n",
        "    # MODIFIED: Use the properties (automatically positive)\n",
        "    damping = model.damping\n",
        "    stiffness = model.stiffness\n",
        "    gravity = 9.81\n",
        "\n",
        "    # The physics equation (unchanged)\n",
        "    physics_equation = 0.01*(acceleration + (damping/(mass*height**2)) * velocity + (stiffness/(mass*height**2) - gravity/height) * position)\n",
        "\n",
        "    # Return how much the model violates physics (smaller = better)\n",
        "    return torch.mean(physics_equation**2)\n",
        "\n",
        "# NEW: Parameter regularization function\n",
        "def parameter_regularization_loss(model):\n",
        "    \"\"\"\n",
        "    Keep parameters in physiologically reasonable ranges.\n",
        "    Damping: 1-20 Nm⋅s/rad, Stiffness: 10-500 Nm/rad\n",
        "    \"\"\"\n",
        "    damping = model.damping\n",
        "    stiffness = model.stiffness\n",
        "\n",
        "    # Soft constraints using smooth penalty functions\n",
        "    damping_penalty = torch.relu(damping - 20.0)**2 + torch.relu(1.0 - damping)**2\n",
        "    stiffness_penalty = torch.relu(stiffness - 500.0)**2 + torch.relu(10.0 - stiffness)**2\n",
        "\n",
        "    return damping_penalty + stiffness_penalty\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: MODIFIED TRAINING WITH MULTI-PHASE APPROACH\n",
        "# ============================================================================\n",
        "\n",
        "def train_simple_pinn(model, time, cop_data, subject_info, epochs=10000):\n",
        "    \"\"\"\n",
        "    Train the neural network using both data and physics.\n",
        "    MODIFIED: Multi-phase training and parameter regularization\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    num_data_points = min(len(time), 20000)\n",
        "    t_tensor = torch.tensor(time[:num_data_points].reshape(-1, 1), dtype=torch.float32)\n",
        "    cop_tensor = torch.tensor(cop_data[:num_data_points], dtype=torch.float32)\n",
        "\n",
        "    # MODIFIED: Different optimizers for different phases\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training history\n",
        "    losses = []\n",
        "    damping_history = []\n",
        "    stiffness_history = []\n",
        "\n",
        "    # MODIFIED: Multi-phase training schedule\n",
        "    phase_configs = [\n",
        "        {'epochs': epochs//4, 'lambda_data': 1.0, 'lambda_physics': 0.1, 'lambda_reg': 0.01},\n",
        "        {'epochs': epochs//4, 'lambda_data': 1.0, 'lambda_physics': 0.3, 'lambda_reg': 0.05},\n",
        "        {'epochs': epochs//4, 'lambda_data': 1.0, 'lambda_physics': 0.7, 'lambda_reg': 0.1},\n",
        "        {'epochs': epochs//4, 'lambda_data': 1.0, 'lambda_physics': 1.0, 'lambda_reg': 0.2}\n",
        "    ]\n",
        "\n",
        "    print(f\"Starting multi-phase training with {num_data_points} data points...\")\n",
        "\n",
        "    epoch = 0\n",
        "    for phase_idx, config in enumerate(phase_configs):\n",
        "        print(f\"\\n--- Phase {phase_idx + 1}/4 ---\")\n",
        "        print(f\"Data weight: {config['lambda_data']}, Physics weight: {config['lambda_physics']}, Regularization: {config['lambda_reg']}\")\n",
        "\n",
        "        for phase_epoch in range(config['epochs']):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 1. Data loss: how well does model fit the measured data?\n",
        "            predictions = model(t_tensor)\n",
        "            data_loss = nn.MSELoss()(predictions, cop_tensor)\n",
        "\n",
        "            # 2. Physics loss: how well does model follow physics?\n",
        "            random_indices = torch.randint(0, num_data_points, (500, 1))\n",
        "            random_times = t_tensor[random_indices]\n",
        "            phys_loss = physics_loss(model, random_times, subject_info['weight'], subject_info['height'])\n",
        "\n",
        "            # 3. MODIFIED: Add parameter regularization\n",
        "            reg_loss = parameter_regularization_loss(model)\n",
        "\n",
        "            # MODIFIED: Weighted combination based on phase\n",
        "            total_loss = (config['lambda_data'] * data_loss +\n",
        "                         config['lambda_physics'] * phys_loss +\n",
        "                         config['lambda_reg'] * reg_loss)\n",
        "\n",
        "            # Update the model\n",
        "            total_loss.backward()\n",
        "\n",
        "            # MODIFIED: Gradient clipping to prevent instability\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track progress\n",
        "            losses.append(total_loss.item())\n",
        "            damping_history.append(model.damping.item())\n",
        "            stiffness_history.append(model.stiffness.item())\n",
        "\n",
        "            # Print progress\n",
        "            if epoch % 500 == 0:\n",
        "                print(f\"Epoch {epoch}: Total Loss = {total_loss:.6f}\")\n",
        "                print(f\"  Damping: {model.damping.item():.4f}, Stiffness: {model.stiffness.item():.4f}\")\n",
        "                print(f\"  Data: {data_loss.item():.6f}, Physics: {phys_loss.item():.6f}, Reg: {reg_loss.item():.6f}\")\n",
        "\n",
        "            epoch += 1\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model, losses, damping_history, stiffness_history\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: MODIFIED ANALYSIS WITH BETTER PARAMETER REPORTING\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_results(model, time, cop_data, subject_info):\n",
        "    \"\"\"\n",
        "    Analyze how well the PINN model performed with comprehensive plots.\n",
        "    MODIFIED: Better parameter reporting\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert time to tensor for predictions\n",
        "    t_tensor = torch.tensor(time.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "    # Get model predictions\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(t_tensor).numpy()\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    true_x, true_y = cop_data[:, 0], cop_data[:, 1]\n",
        "    pred_x, pred_y = predictions[:, 0], predictions[:, 1]\n",
        "\n",
        "    rmse_x = np.sqrt(mean_squared_error(true_x, pred_x))\n",
        "    rmse_y = np.sqrt(mean_squared_error(true_y, pred_y))\n",
        "    r2_x = r2_score(true_x, pred_x)\n",
        "    r2_y = r2_score(true_y, pred_y)\n",
        "\n",
        "    print(f\"\\nPerformance Metrics:\")\n",
        "    print(f\"RMSE X: {rmse_x:.3f}, R² X: {r2_x:.3f}\")\n",
        "    print(f\"RMSE Y: {rmse_y:.3f}, R² Y: {r2_y:.3f}\")\n",
        "    print(f\"\\nLearned Physics Parameters:\")\n",
        "    print(f\"Damping: {model.damping.item():.4f} Nm⋅s/rad\")\n",
        "    print(f\"Stiffness: {model.stiffness.item():.4f} Nm/rad\")\n",
        "\n",
        "    # MODIFIED: Check if parameters are in physiological range\n",
        "    damping_val = model.damping.item()\n",
        "    stiffness_val = model.stiffness.item()\n",
        "\n",
        "    damping_ok = 1.0 <= damping_val <= 20.0\n",
        "    stiffness_ok = 10.0 <= stiffness_val <= 500.0\n",
        "\n",
        "    print(f\"Parameter validation:\")\n",
        "    print(f\"  Damping {'✓' if damping_ok else '✗'} (physiological range: 1-20)\")\n",
        "    print(f\"  Stiffness {'✓' if stiffness_ok else '✗'} (physiological range: 10-500)\")\n",
        "\n",
        "    # Create the original 2x3 plot layout (unchanged plotting code)\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "    # PLOT 1: COP_x Time Series\n",
        "    axes[0, 0].plot(time, true_x, 'b-', label='True', alpha=0.7, linewidth=1.5)\n",
        "    axes[0, 0].plot(time, pred_x, 'r--', label='PINN', alpha=0.7, linewidth=1.5)\n",
        "    axes[0, 0].set_xlabel('Time (s)')\n",
        "    axes[0, 0].set_ylabel('COP_x (cm)')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].set_title(f'COP X-direction (RMSE: {rmse_x:.3f}, R²: {r2_x:.3f})')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # PLOT 2: COP_y Time Series\n",
        "    axes[0, 1].plot(time, true_y, 'b-', label='True', alpha=0.7, linewidth=1.5)\n",
        "    axes[0, 1].plot(time, pred_y, 'r--', label='PINN', alpha=0.7, linewidth=1.5)\n",
        "    axes[0, 1].set_xlabel('Time (s)')\n",
        "    axes[0, 1].set_ylabel('COP_y (cm)')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].set_title(f'COP Y-direction (RMSE: {rmse_y:.3f}, R²: {r2_y:.3f})')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # PLOT 3: Correlation Plot (True vs Predicted)\n",
        "    axes[0, 2].scatter(true_x, pred_x, alpha=0.5, s=10)\n",
        "    axes[0, 2].plot([true_x.min(), true_x.max()],\n",
        "                    [true_x.min(), true_x.max()], 'k--', alpha=0.7)\n",
        "    axes[0, 2].set_xlabel('True COP_x')\n",
        "    axes[0, 2].set_ylabel('Predicted COP_x')\n",
        "    axes[0, 2].set_title('Correlation COP_x')\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    # PLOT 4: COP Trajectory (Stabilogram)\n",
        "    axes[1, 0].plot(true_x, true_y, 'b-', label='True', alpha=0.7, linewidth=1)\n",
        "    axes[1, 0].plot(pred_x, pred_y, 'r--', label='PINN', alpha=0.7, linewidth=1)\n",
        "    axes[1, 0].set_xlabel('COP_x (cm)')\n",
        "    axes[1, 0].set_ylabel('COP_y (cm)')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].set_title('COP Trajectory (Stabilogram)')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    axes[1, 0].axis('equal')\n",
        "\n",
        "    # PLOT 5: Error Analysis\n",
        "    error_x = true_x - pred_x\n",
        "    error_y = true_y - pred_y\n",
        "    axes[1, 1].plot(time, error_x, 'g-', label='Error X', alpha=0.7, linewidth=1)\n",
        "    axes[1, 1].plot(time, error_y, 'm-', label='Error Y', alpha=0.7, linewidth=1)\n",
        "    axes[1, 1].axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "    axes[1, 1].set_xlabel('Time (s)')\n",
        "    axes[1, 1].set_ylabel('Error (cm)')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].set_title('Prediction Errors')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # PLOT 6: Frequency Domain Analysis\n",
        "    from scipy.fft import fft, fftfreq\n",
        "    N = len(true_x)\n",
        "    T = time[1] - time[0]\n",
        "    freqs = fftfreq(N, T)[:N//2]\n",
        "\n",
        "    fft_true_x = np.abs(fft(true_x))[:N//2]\n",
        "    fft_pred_x = np.abs(fft(pred_x))[:N//2]\n",
        "\n",
        "    axes[1, 2].plot(freqs[1:], fft_true_x[1:], 'b-', label='True X', alpha=0.7, linewidth=1)\n",
        "    axes[1, 2].plot(freqs[1:], fft_pred_x[1:], 'r--', label='PINN X', alpha=0.7, linewidth=1)\n",
        "    axes[1, 2].set_xlabel('Frequency (Hz)')\n",
        "    axes[1, 2].set_ylabel('Amplitude')\n",
        "    axes[1, 2].set_title('Frequency Spectrum (COP_x)')\n",
        "    axes[1, 2].legend()\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# REMAINING FUNCTIONS UNCHANGED\n",
        "# ============================================================================\n",
        "\n",
        "def plot_physics_parameter_evolution(damping_history, stiffness_history, record_name):\n",
        "    \"\"\"\n",
        "    Plots the evolution of learned damping and stiffness values over epochs.\n",
        "    \"\"\"\n",
        "    epochs = range(len(damping_history))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, damping_history, label='Learned Damping')\n",
        "    plt.plot(epochs, stiffness_history, label='Learned Stiffness')\n",
        "\n",
        "    # MODIFIED: Add physiological range indicators\n",
        "    plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Damping Range (1-20)')\n",
        "    plt.axhline(y=20.0, color='red', linestyle='--', alpha=0.5)\n",
        "    plt.axhline(y=10.0, color='blue', linestyle='--', alpha=0.5, label='Stiffness Range (10-500)')\n",
        "    plt.axhline(y=500.0, color='blue', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Parameter Value')\n",
        "    plt.title(f'Evolution of Learned Physics Parameters During Training ({record_name})')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "# NEW: Function to plot scatter plots of parameters vs subject characteristics\n",
        "def plot_parameter_vs_subject_characteristics(all_mass, all_height, all_damping, all_stiffness):\n",
        "    \"\"\"\n",
        "    Generates scatter plots of learned parameters vs subject mass and height.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Damping vs. Mass\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.scatter(all_mass, all_damping, alpha=0.7)\n",
        "    plt.xlabel('Mass (kg)')\n",
        "    plt.ylabel('Damping (Nm⋅s/rad)')\n",
        "    plt.title('Learned Damping vs. Subject Mass')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Damping vs. Height\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.scatter(all_height, all_damping, alpha=0.7)\n",
        "    plt.xlabel('Height (m)')\n",
        "    plt.ylabel('Damping (Nm⋅s/rad)')\n",
        "    plt.title('Learned Damping vs. Subject Height')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Stiffness vs. Mass\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.scatter(all_mass, all_stiffness, alpha=0.7)\n",
        "    plt.xlabel('Mass (kg)')\n",
        "    plt.ylabel('Stiffness (Nm/rad)')\n",
        "    plt.title('Learned Stiffness vs. Subject Mass')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Stiffness vs. Height\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.scatter(all_height, all_stiffness, alpha=0.7)\n",
        "    plt.xlabel('Height (m)')\n",
        "    plt.ylabel('Stiffness (Nm/rad)')\n",
        "    plt.title('Learned Stiffness vs. Subject Height')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# NEW: Function to plot parameter evolution across files\n",
        "def plot_parameter_evolution_across_files(all_damping, all_stiffness, all_record_names):\n",
        "    \"\"\"\n",
        "    Plots the evolution of learned damping and stiffness values across processed files.\n",
        "    \"\"\"\n",
        "    file_indices = range(len(all_damping))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(file_indices, all_damping, marker='o', linestyle='-', label='Learned Damping')\n",
        "    plt.plot(file_indices, all_stiffness, marker='o', linestyle='-', label='Learned Stiffness')\n",
        "\n",
        "    plt.xlabel('File Index')\n",
        "    plt.ylabel('Parameter Value')\n",
        "    plt.title('Evolution of Learned Physics Parameters Across Files')\n",
        "    plt.xticks(file_indices, all_record_names, rotation=90)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def run_balance_analysis(model, data_path):\n",
        "    \"\"\"Main function - UNCHANGED\"\"\"\n",
        "    print(\"=== SIMPLIFIED PINN BALANCE ANALYSIS ===\")\n",
        "\n",
        "    print(\"\\n1. Loading data...\")\n",
        "    time, cop_data, subject_info = load_balance_data(data_path)\n",
        "    print(f\"   Loaded {len(time)} data points\")\n",
        "    print(f\"   Subject: {subject_info['weight']:.1f} kg, {subject_info['height']:.2f} m\")\n",
        "\n",
        "    print(\"\\n2. Training PINN model...\")\n",
        "    model, loss_history, damping_history, stiffness_history = train_simple_pinn(model, time, cop_data, subject_info)\n",
        "\n",
        "    print(\"\\n3. Analyzing results...\")\n",
        "    analyze_results(model, time, cop_data, subject_info)\n",
        "\n",
        "    print(\"\\n4. Plotting physics parameter evolution...\")\n",
        "    record_name = os.path.basename(data_path)\n",
        "    plot_physics_parameter_evolution(damping_history, stiffness_history, record_name)\n",
        "\n",
        "    print(\"\\nAnalysis complete!\")\n",
        "    return model # Return the trained model\n",
        "\n",
        "def analyze_multiple_files(folder_path, save_plots=True, results_folder=\"results\"):\n",
        "    \"\"\"Batch processing - MODIFIED\"\"\"\n",
        "    if save_plots:\n",
        "        os.makedirs(results_folder, exist_ok=True)\n",
        "\n",
        "    dat_files = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith('.dat'):\n",
        "            record_name = file[:-4]\n",
        "            dat_files.append(os.path.join(folder_path, record_name))\n",
        "\n",
        "    print(f\"Found {len(dat_files)} WFDB records to process\")\n",
        "\n",
        "    # MODIFIED: Initialize lists to store results\n",
        "    all_mass = []\n",
        "    all_height = []\n",
        "    all_damping = []\n",
        "    all_stiffness = []\n",
        "    all_record_names = [] # Store record names for plotting labels\n",
        "\n",
        "    # NOTE: The model is re-initialized for each file as per the original code's structure.\n",
        "    # If you intended to use a single model trained sequentially on all files,\n",
        "    # the model initialization should be moved outside the loop.\n",
        "    print(\"\\nInitializing a PINN model for each file.\")\n",
        "\n",
        "\n",
        "    for i, record_path in enumerate(dat_files):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Processing file {i+1}/{len(dat_files)}: {os.path.basename(record_path)}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        try:\n",
        "            # Initialize a new model for each file\n",
        "            model = SimpleBalancePINN()\n",
        "\n",
        "            # Load data and train model\n",
        "            time, cop_data, subject_info = load_balance_data(record_path)\n",
        "            print(f\"   Loaded {len(time)} data points\")\n",
        "            print(f\"   Subject: {subject_info['weight']:.1f} kg, {subject_info['height']:.2f} m\")\n",
        "\n",
        "            print(\"\\n2. Training PINN model...\")\n",
        "            # Pass subject_info to train_simple_pinn\n",
        "            model, loss_history, damping_history, stiffness_history = train_simple_pinn(model, time, cop_data, subject_info)\n",
        "\n",
        "\n",
        "            # MODIFIED: Store the results\n",
        "            all_mass.append(subject_info['weight'])\n",
        "            all_height.append(subject_info['height'])\n",
        "            all_damping.append(model.damping.item())\n",
        "            all_stiffness.append(model.stiffness.item())\n",
        "            all_record_names.append(os.path.basename(record_path))\n",
        "\n",
        "\n",
        "            print(\"\\n3. Analyzing results...\")\n",
        "            analyze_results(model, time, cop_data, subject_info) # Pass subject_info here\n",
        "\n",
        "            print(\"\\n4. Plotting physics parameter evolution...\")\n",
        "            record_name = os.path.basename(record_path)\n",
        "            plot_physics_parameter_evolution(damping_history, stiffness_history, record_name)\n",
        "\n",
        "            if save_plots:\n",
        "                # Save analysis plot\n",
        "                analysis_plot_filename = os.path.join(results_folder, f\"{record_name}_analysis.png\")\n",
        "                try:\n",
        "                    # Ensure the plot is created before saving\n",
        "                    plt.figure(figsize=(15, 10)) # Create a new figure for analysis plot\n",
        "                    analyze_results(model, time, cop_data, subject_info) # Re-generate plot\n",
        "                    plt.savefig(analysis_plot_filename, dpi=300, bbox_inches='tight')\n",
        "                    plt.close() # Close the figure to free memory\n",
        "                    print(f\"Analysis plot saved to: {analysis_plot_filename}\")\n",
        "                except Exception as save_e:\n",
        "                    print(f\"Error saving analysis plot for {os.path.basename(record_path)}: {save_e}\")\n",
        "\n",
        "\n",
        "                # Save parameter evolution plot\n",
        "                param_plot_filename = os.path.join(results_folder, f\"{record_name}_params_evolution.png\")\n",
        "                try:\n",
        "                     plt.figure(figsize=(10, 6)) # Create a new figure for parameter evolution plot\n",
        "                     plot_physics_parameter_evolution(damping_history, stiffness_history, record_name) # Re-generate plot\n",
        "                     plt.savefig(param_plot_filename, dpi=300, bbox_inches='tight')\n",
        "                     plt.close() # Close the figure\n",
        "                     print(f\"Parameter evolution plot saved to: {param_plot_filename}\")\n",
        "                except Exception as save_e:\n",
        "                    print(f\"Error saving parameter evolution plot for {os.path.basename(record_path)}: {save_e}\")\n",
        "\n",
        "\n",
        "            print(f\"✓ Successfully processed {os.path.basename(record_path)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error processing {os.path.basename(record_path)}: {e}\")\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"All files processed!\")\n",
        "    if save_plots:\n",
        "        print(f\"Results saved to: {results_folder}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # MODIFIED: Return the collected data\n",
        "    return all_mass, all_height, all_damping, all_stiffness, all_record_names\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN LOOP - MODIFIED TO CAPTURE RETURN VALUES AND ADD NEW PLOTS\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_folder = \"/content/drive/MyDrive/human-balance-evaluation-database-1.0.0\"\n",
        "    # MODIFIED: Capture the returned data\n",
        "    all_mass, all_height, all_damping, all_stiffness, all_record_names = analyze_multiple_files(data_folder)\n",
        "\n",
        "    # Now you have the data in these lists for further plotting/analysis\n",
        "    print(\"\\nCollected data from all files:\")\n",
        "    print(f\"Masses: {all_mass[:10]}...\")\n",
        "    print(f\"Heights: {all_height[:10]}...\")\n",
        "    print(f\"Damping: {all_damping[:10]}...\")\n",
        "    print(f\"Stiffness: {all_stiffness[:10]}...\")\n",
        "    print(f\"Record Names: {all_record_names[:10]}...\")\n",
        "\n",
        "    # NEW: Generate the requested scatter plots\n",
        "    print(\"\\nGenerating parameter vs. subject characteristics plots...\")\n",
        "    plot_parameter_vs_subject_characteristics(all_mass, all_height, all_damping, all_stiffness)\n",
        "\n",
        "    # NEW: Generate the parameter evolution across files plot\n",
        "    print(\"\\nGenerating parameter evolution across files plot...\")\n",
        "    plot_parameter_evolution_across_files(all_damping, all_stiffness, all_record_names)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "=== KEY MODIFICATIONS MADE TO FIX DAMPING ISSUE ===\n",
        "\n",
        "1. **Log Parameterization**:\n",
        "   - Changed from direct parameters to log_damping/log_stiffness\n",
        "   - Uses properties to ensure always positive values\n",
        "   - Better gradients during training\n",
        "\n",
        "2. **Parameter Regularization**:\n",
        "   - Added parameter_regularization_loss() function\n",
        "   - Keeps damping in 1-20 Nm⋅s/rad range\n",
        "   - Keeps stiffness in 10-500 Nm/rad range\n",
        "\n",
        "3. **Multi-Phase Training**:\n",
        "   - Gradually increases physics and regularization weights\n",
        "   - Prevents premature convergence to zero damping\n",
        "   - Better balance between fitting data and physics\n",
        "\n",
        "4. **Gradient Clipping**:\n",
        "   - Prevents training instability\n",
        "   - Helps maintain reasonable parameter values\n",
        "\n",
        "5. **Better Initialization**:\n",
        "   - Damping starts at 5.0 (reasonable value)\n",
        "   - Stiffness starts at 50.0 (reasonable value)\n",
        "\n",
        "6. **Validation Feedback**:\n",
        "   - Reports if parameters are in physiological ranges\n",
        "   - Shows reference lines in parameter evolution plots\n",
        "\n",
        "These minimal changes should prevent the damping from going to zero while\n",
        "keeping the same overall structure and functionality of your original code.\n",
        "\n",
        "=== NEW ADDITIONS FOR ANALYSIS ===\n",
        "\n",
        "- **Collected Data**: The `analyze_multiple_files` function now collects the final learned damping, stiffness, subject mass, and height for each file.\n",
        "- **Parameter vs. Subject Plots**: Added `plot_parameter_vs_subject_characteristics` function to visualize the relationship between learned parameters and subject mass/height.\n",
        "- **Parameter Evolution Across Files**: Added `plot_parameter_evolution_across_files` function to show how learned parameters change from one processed file to the next.\n",
        "- **Main Loop Update**: The `if __name__ == \"__main__\":` block now calls the new plotting functions after all files have been processed.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wfdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSDpTPnn7pOV",
        "outputId": "35095c4a-cf23-4716-dc4b-fc9849c73f60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.12.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.1)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2025.8.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n",
            "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas, wfdb\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.3.2 wfdb-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-QE6VeH7tBC",
        "outputId": "88305365-c781-4ad4-bb52-0e1d91cb071c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wfdb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "UfRiS9yo3Q1Q",
        "outputId": "b8f74f38-91e0-4fbf-a288-101497d58064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.12.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.1)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2025.8.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n",
            "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas, wfdb\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.3.2 wfdb-4.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              },
              "id": "1eef9a95f9484eee97d3df541cf98db4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a99b11d4"
      },
      "source": [
        "# Task\n",
        "Modify the code in cell 'SFg5KXxl24tH' to generate scatter plots of damping vs. mass, damping vs. height, stiffness vs. mass, and stiffness vs. height after processing multiple files, showing all previous values in each plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad76d0a8"
      },
      "source": [
        "## Collect data\n",
        "\n",
        "### Subtask:\n",
        "Modify the `analyze_multiple_files` function to store the subject's mass, height, learned damping, and learned stiffness for each processed file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "212fffc2"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `analyze_multiple_files` function to store the learned parameters and subject information. This involves initializing empty lists and appending the relevant data within the processing loop.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ca2ebb"
      },
      "source": [
        "def analyze_multiple_files(folder_path, save_plots=True, results_folder=\"results\"):\n",
        "    \"\"\"Batch processing - MODIFIED\"\"\"\n",
        "    if save_plots:\n",
        "        os.makedirs(results_folder, exist_ok=True)\n",
        "\n",
        "    dat_files = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith('.dat'):\n",
        "            record_name = file[:-4]\n",
        "            dat_files.append(os.path.join(folder_path, record_name))\n",
        "\n",
        "    print(f\"Found {len(dat_files)} WFDB records to process\")\n",
        "\n",
        "    # MODIFIED: Initialize lists to store results\n",
        "    all_mass = []\n",
        "    all_height = []\n",
        "    all_damping = []\n",
        "    all_stiffness = []\n",
        "    all_record_names = [] # Store record names for plotting labels\n",
        "\n",
        "    model = SimpleBalancePINN()\n",
        "    print(\"\\nInitialized a single PINN model for batch processing.\")\n",
        "\n",
        "    for i, record_path in enumerate(dat_files):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Processing file {i+1}/{len(dat_files)}: {os.path.basename(record_path)}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        try:\n",
        "            # Load data and train model\n",
        "            time, cop_data, subject_info = load_balance_data(record_path)\n",
        "            print(f\"   Loaded {len(time)} data points\")\n",
        "            print(f\"   Subject: {subject_info['weight']:.1f} kg, {subject_info['height']:.2f} m\")\n",
        "\n",
        "            print(\"\\n2. Training PINN model...\")\n",
        "            # Pass subject_info to train_simple_pinn\n",
        "            model, loss_history, damping_history, stiffness_history = train_simple_pinn(model, time, cop_data, subject_info)\n",
        "\n",
        "\n",
        "            # MODIFIED: Store the results\n",
        "            all_mass.append(subject_info['weight'])\n",
        "            all_height.append(subject_info['height'])\n",
        "            all_damping.append(model.damping.item())\n",
        "            all_stiffness.append(model.stiffness.item())\n",
        "            all_record_names.append(os.path.basename(record_path))\n",
        "\n",
        "\n",
        "            print(\"\\n3. Analyzing results...\")\n",
        "            analyze_results(model, time, cop_data, subject_info) # Pass subject_info here\n",
        "\n",
        "            print(\"\\n4. Plotting physics parameter evolution...\")\n",
        "            record_name = os.path.basename(record_path)\n",
        "            plot_physics_parameter_evolution(damping_history, stiffness_history, record_name)\n",
        "\n",
        "            if save_plots:\n",
        "                # Save analysis plot\n",
        "                analysis_plot_filename = os.path.join(results_folder, f\"{record_name}_analysis.png\")\n",
        "                try:\n",
        "                    # Ensure the plot is created before saving\n",
        "                    plt.figure(figsize=(15, 10)) # Create a new figure for analysis plot\n",
        "                    analyze_results(model, time, cop_data, subject_info) # Re-generate plot\n",
        "                    plt.savefig(analysis_plot_filename, dpi=300, bbox_inches='tight')\n",
        "                    plt.close() # Close the figure to free memory\n",
        "                    print(f\"Analysis plot saved to: {analysis_plot_filename}\")\n",
        "                except Exception as save_e:\n",
        "                    print(f\"Error saving analysis plot for {os.path.basename(record_path)}: {save_e}\")\n",
        "\n",
        "\n",
        "                # Save parameter evolution plot\n",
        "                param_plot_filename = os.path.join(results_folder, f\"{record_name}_params_evolution.png\")\n",
        "                try:\n",
        "                     plt.figure(figsize=(10, 6)) # Create a new figure for parameter evolution plot\n",
        "                     plot_physics_parameter_evolution(damping_history, stiffness_history, record_name) # Re-generate plot\n",
        "                     plt.savefig(param_plot_filename, dpi=300, bbox_inches='tight')\n",
        "                     plt.close() # Close the figure\n",
        "                     print(f\"Parameter evolution plot saved to: {param_plot_filename}\")\n",
        "                except Exception as save_e:\n",
        "                    print(f\"Error saving parameter evolution plot for {os.path.basename(record_path)}: {save_e}\")\n",
        "\n",
        "\n",
        "            print(f\"✓ Successfully processed {os.path.basename(record_path)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error processing {os.path.basename(record_path)}: {e}\")\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"All files processed!\")\n",
        "    if save_plots:\n",
        "        print(f\"Results saved to: {results_folder}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # MODIFIED: Return the collected data\n",
        "    return all_mass, all_height, all_damping, all_stiffness, all_record_names\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN LOOP - MODIFIED TO CAPTURE RETURN VALUES\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_folder = \"/content/drive/MyDrive/human-balance-evaluation-database-1.0.0\"\n",
        "    # MODIFIED: Capture the returned data\n",
        "    all_mass, all_height, all_damping, all_stiffness, all_record_names = analyze_multiple_files(data_folder)\n",
        "\n",
        "    # Now you have the data in these lists for further plotting/analysis\n",
        "    print(\"\\nCollected data from all files:\")\n",
        "    print(f\"Masses: {all_mass[:10]}...\")\n",
        "    print(f\"Heights: {all_height[:10]}...\")\n",
        "    print(f\"Damping: {all_damping[:10]}...\")\n",
        "    print(f\"Stiffness: {all_stiffness[:10]}...\")\n",
        "    print(f\"Record Names: {all_record_names[:10]}...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}