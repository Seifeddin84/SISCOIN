{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu2HEGj7vk0fghuaCFZHxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seifeddin84/SISCOIN/blob/main/PINN_inverted_pendulum_for_human_quiet_balance_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFg5KXxl24tH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "SIMPLIFIED PHYSICS-INFORMED NEURAL NETWORKS FOR HUMAN BALANCE\n",
        "===========================================================================\n",
        "> A code designed and generated by google colab gemini + claude ai\n",
        "\n",
        "MODIFICATIONS TO FIX DAMPING ISSUE:\n",
        "1. Better initialization of damping and stiffness parameters\n",
        "2. Added parameter regularization loss\n",
        "3. Multi-phase training to gradually enforce physics\n",
        "4. Constraint damping to physiological range\n",
        "\n",
        "REQUIRED DATA: CSV files with columns Fx, Fy, Fz, Mx, My, Mz, COPx, COPy\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import wfdb\n",
        "import os\n",
        "import re\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: SIMPLE DATA LOADER (UNCHANGED)\n",
        "# ============================================================================\n",
        "\n",
        "def load_balance_data(file_path):\n",
        "    \"\"\"\n",
        "    Load balance data from WFDB files or CSV files.\n",
        "    Returns: time, COP data, and subject info\n",
        "    \"\"\"\n",
        "\n",
        "    # Try to load as WFDB first\n",
        "    if os.path.exists(file_path + '.dat') and os.path.exists(file_path + '.hea'):\n",
        "        print(f\"Loading WFDB record: {file_path}\")\n",
        "\n",
        "        # Load the WFDB record\n",
        "        record = wfdb.rdrecord(file_path)\n",
        "        data = pd.DataFrame(record.p_signal, columns=record.sig_name)\n",
        "        sample_rate = record.fs\n",
        "\n",
        "        # Extract subject info from .hea file, the mass m and hieght l\n",
        "        subject_info = {'weight': 75.0, 'height': 1.70}  # defaults\n",
        "\n",
        "        hea_file = file_path + '.hea'\n",
        "        if os.path.exists(hea_file):\n",
        "            with open(hea_file, 'r') as f:\n",
        "                content = f.read()\n",
        "                # Look for height and weight in comments\n",
        "                height_match = re.search(r'#Height:\\s*(\\d+\\.?\\d*)', content)\n",
        "                weight_match = re.search(r'#Weight:\\s*(\\d+\\.?\\d*)', content)\n",
        "\n",
        "                if height_match:\n",
        "                    subject_info['height'] = float(height_match.group(1)) * 0.55 / 100 # convert cm to m\n",
        "                if weight_match:\n",
        "                    subject_info['weight'] = float(weight_match.group(1))\n",
        "\n",
        "    else:\n",
        "        # Try to load as CSV\n",
        "        print(f\"Loading CSV file: {file_path}\")\n",
        "        data = pd.read_csv(file_path)\n",
        "        sample_rate = 50  # assume 100 Hz if not specified\n",
        "        subject_info = {'weight': 75.0, 'height': 1.70}  # defaults for CSV\n",
        "\n",
        "    # Make sure we have the required columns\n",
        "    required_cols = ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz', 'COPx', 'COPy']\n",
        "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
        "\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing columns: {missing_cols}\")\n",
        "\n",
        "    # Create time vector\n",
        "    time = np.linspace(0, len(data)/sample_rate, len(data))\n",
        "\n",
        "    # Extract COP data (what we want to predict)\n",
        "    cop_data = data[['COPx', 'COPy']].values\n",
        "\n",
        "    return time, cop_data, subject_info\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: MODIFIED NEURAL NETWORK WITH BETTER PARAMETER INITIALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "class SimpleBalancePINN(nn.Module):\n",
        "    \"\"\"\n",
        "    A simplified neural network for balance prediction.\n",
        "    MODIFIED: Better parameter initialization and constraints\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Simple 3-layer network (unchanged)\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(1, 100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 2)\n",
        "        )\n",
        "\n",
        "        # Initialize weights for better training\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                nn.init.xavier_normal_(layer.weight)\n",
        "\n",
        "        # MODIFIED: Better initialization for physics parameters\n",
        "        # Use log parameterization to ensure positivity and better gradients\n",
        "        self.log_damping = nn.Parameter(torch.tensor(np.log(5.0), dtype=torch.float32))  # exp(log(5)) = 5\n",
        "        self.log_stiffness = nn.Parameter(torch.tensor(np.log(50.0), dtype=torch.float32))  # exp(log(50)) = 50\n",
        "\n",
        "    @property\n",
        "    def damping(self):\n",
        "        \"\"\"Always positive damping via exponential\"\"\"\n",
        "        return torch.exp(self.log_damping)\n",
        "\n",
        "    @property\n",
        "    def stiffness(self):\n",
        "        \"\"\"Always positive stiffness via exponential\"\"\"\n",
        "        return torch.exp(self.log_stiffness)\n",
        "\n",
        "    def forward(self, t):\n",
        "        \"\"\"Given time t, predict COP position\"\"\"\n",
        "        return self.layers(t)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: MODIFIED PHYSICS EQUATIONS WITH REGULARIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def physics_loss(model, time_points, mass, height):\n",
        "    \"\"\"\n",
        "    Calculate how well the model follows physics laws.\n",
        "    MODIFIED: Uses the new property-based parameters\n",
        "    \"\"\"\n",
        "\n",
        "    # Enable gradients for computing derivatives\n",
        "    time_points.requires_grad_(True)\n",
        "\n",
        "    # Get model predictions\n",
        "    position = model(time_points)\n",
        "\n",
        "    # Calculate velocity (first derivative)\n",
        "    velocity = torch.autograd.grad(position.sum(), time_points, create_graph=True)[0]\n",
        "\n",
        "    # Calculate acceleration (second derivative)\n",
        "    acceleration = torch.autograd.grad(velocity.sum(), time_points, create_graph=True)[0]\n",
        "\n",
        "    # MODIFIED: Use the properties (automatically positive)\n",
        "    damping = model.damping\n",
        "    stiffness = model.stiffness\n",
        "    gravity = 9.81\n",
        "\n",
        "    # The physics equation (unchanged)\n",
        "    physics_equation = 0.01*(acceleration + (damping/(mass*height**2)) * velocity + (stiffness/(mass*height**2) - gravity/height) * position)\n",
        "\n",
        "    # Return how much the model violates physics (smaller = better)\n",
        "    return torch.mean(physics_equation**2)\n",
        "\n",
        "# NEW: Parameter regularization function\n",
        "def parameter_regularization_loss(model):\n",
        "    \"\"\"\n",
        "    Keep parameters in physiologically reasonable ranges.\n",
        "    Damping: 1-20 Nmâ‹…s/rad, Stiffness: 10-500 Nm/rad\n",
        "    \"\"\"\n",
        "    damping = model.damping\n",
        "    stiffness = model.stiffness\n",
        "\n",
        "    # Soft constraints using smooth penalty functions\n",
        "    damping_penalty = torch.relu(damping - 20.0)**2 + torch.relu(1.0 - damping)**2\n",
        "    stiffness_penalty = torch.relu(stiffness - 500.0)**2 + torch.relu(10.0 - stiffness)**2\n",
        "\n",
        "    return damping_penalty + stiffness_penalty\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: MODIFIED TRAINING WITH MULTI-PHASE APPROACH\n",
        "# ============================================================================\n",
        "\n",
        "def train_simple_pinn(model, time, cop_data, subject_info, epochs=10000):\n",
        "    \"\"\"\n",
        "    Train the neural network using both data and physics.\n",
        "    MODIFIED: Multi-phase training and parameter regularization\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data to PyTorch tensors\n",
        "    num_data_points = min(len(time), 20000)\n",
        "    t_tensor = torch.tensor(time[:num_data_points].reshape(-1, 1), dtype=torch.float32)\n",
        "    cop_tensor = torch.tensor(cop_data[:num_data_points], dtype=torch.float32)\n",
        "\n",
        "    # MODIFIED: Different optimizers for different phases\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training history\n",
        "    losses = []\n",
        "    damping_history = []\n",
        "    stiffness_history = []\n",
        "\n",
        "    # MODIFIED: Multi-phase training schedule\n",
        "    phase_configs = [\n",
        "        {'epochs': epochs//4, 'lambda_data': 1.0, 'lambda_physics': 0.1, 'lambda_reg': 0.01},\n",
        "        {'epochs': epochs//4, 'lambda_data': 1.0, 'lambda_physics': 0.3, 'lambda_reg': 0.05},\n",
        "        {'epochs': epochs//4, 'lambda_data': 1.0, 'lambda_physics': 0.7, 'lambda_reg': 0.1},\n",
        "        {'epochs': epochs//4, 'lambda_data': 1.0, 'lambda_physics': 1.0, 'lambda_reg': 0.2}\n",
        "    ]\n",
        "\n",
        "    print(f\"Starting multi-phase training with {num_data_points} data points...\")\n",
        "\n",
        "    epoch = 0\n",
        "    for phase_idx, config in enumerate(phase_configs):\n",
        "        print(f\"\\n--- Phase {phase_idx + 1}/4 ---\")\n",
        "        print(f\"Data weight: {config['lambda_data']}, Physics weight: {config['lambda_physics']}, Regularization: {config['lambda_reg']}\")\n",
        "\n",
        "        for phase_epoch in range(config['epochs']):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 1. Data loss: how well does model fit the measured data?\n",
        "            predictions = model(t_tensor)\n",
        "            data_loss = nn.MSELoss()(predictions, cop_tensor)\n",
        "\n",
        "            # 2. Physics loss: how well does model follow physics?\n",
        "            random_indices = torch.randint(0, num_data_points, (500, 1))\n",
        "            random_times = t_tensor[random_indices]\n",
        "            phys_loss = physics_loss(model, random_times, subject_info['weight'], subject_info['height'])\n",
        "\n",
        "            # 3. MODIFIED: Add parameter regularization\n",
        "            reg_loss = parameter_regularization_loss(model)\n",
        "\n",
        "            # MODIFIED: Weighted combination based on phase\n",
        "            total_loss = (config['lambda_data'] * data_loss +\n",
        "                         config['lambda_physics'] * phys_loss +\n",
        "                         config['lambda_reg'] * reg_loss)\n",
        "\n",
        "            # Update the model\n",
        "            total_loss.backward()\n",
        "\n",
        "            # MODIFIED: Gradient clipping to prevent instability\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track progress\n",
        "            losses.append(total_loss.item())\n",
        "            damping_history.append(model.damping.item())\n",
        "            stiffness_history.append(model.stiffness.item())\n",
        "\n",
        "            # Print progress\n",
        "            if epoch % 500 == 0:\n",
        "                print(f\"Epoch {epoch}: Total Loss = {total_loss:.6f}\")\n",
        "                print(f\"  Damping: {model.damping.item():.4f}, Stiffness: {model.stiffness.item():.4f}\")\n",
        "                print(f\"  Data: {data_loss.item():.6f}, Physics: {phys_loss.item():.6f}, Reg: {reg_loss.item():.6f}\")\n",
        "\n",
        "            epoch += 1\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model, losses, damping_history, stiffness_history\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: MODIFIED ANALYSIS WITH BETTER PARAMETER REPORTING\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_results(model, time, cop_data, subject_info):\n",
        "    \"\"\"\n",
        "    Analyze how well the PINN model performed with comprehensive plots.\n",
        "    MODIFIED: Better parameter reporting\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert time to tensor for predictions\n",
        "    t_tensor = torch.tensor(time.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "    # Get model predictions\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(t_tensor).numpy()\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    true_x, true_y = cop_data[:, 0], cop_data[:, 1]\n",
        "    pred_x, pred_y = predictions[:, 0], predictions[:, 1]\n",
        "\n",
        "    rmse_x = np.sqrt(mean_squared_error(true_x, pred_x))\n",
        "    rmse_y = np.sqrt(mean_squared_error(true_y, pred_y))\n",
        "    r2_x = r2_score(true_x, pred_x)\n",
        "    r2_y = r2_score(true_y, pred_y)\n",
        "\n",
        "    print(f\"\\nPerformance Metrics:\")\n",
        "    print(f\"RMSE X: {rmse_x:.3f}, RÂ² X: {r2_x:.3f}\")\n",
        "    print(f\"RMSE Y: {rmse_y:.3f}, RÂ² Y: {r2_y:.3f}\")\n",
        "    print(f\"\\nLearned Physics Parameters:\")\n",
        "    print(f\"Damping: {model.damping.item():.4f} Nmâ‹…s/rad\")\n",
        "    print(f\"Stiffness: {model.stiffness.item():.4f} Nm/rad\")\n",
        "\n",
        "    # MODIFIED: Check if parameters are in physiological range\n",
        "    damping_val = model.damping.item()\n",
        "    stiffness_val = model.stiffness.item()\n",
        "\n",
        "    damping_ok = 1.0 <= damping_val <= 20.0\n",
        "    stiffness_ok = 10.0 <= stiffness_val <= 500.0\n",
        "\n",
        "    print(f\"Parameter validation:\")\n",
        "    print(f\"  Damping {'âœ“' if damping_ok else 'âœ—'} (physiological range: 1-20)\")\n",
        "    print(f\"  Stiffness {'âœ“' if stiffness_ok else 'âœ—'} (physiological range: 10-500)\")\n",
        "\n",
        "    # Create the original 2x3 plot layout (unchanged plotting code)\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "    # PLOT 1: COP_x Time Series\n",
        "    axes[0, 0].plot(time, true_x, 'b-', label='True', alpha=0.7, linewidth=1.5)\n",
        "    axes[0, 0].plot(time, pred_x, 'r--', label='PINN', alpha=0.7, linewidth=1.5)\n",
        "    axes[0, 0].set_xlabel('Time (s)')\n",
        "    axes[0, 0].set_ylabel('COP_x (cm)')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].set_title(f'COP X-direction (RMSE: {rmse_x:.3f}, RÂ²: {r2_x:.3f})')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # PLOT 2: COP_y Time Series\n",
        "    axes[0, 1].plot(time, true_y, 'b-', label='True', alpha=0.7, linewidth=1.5)\n",
        "    axes[0, 1].plot(time, pred_y, 'r--', label='PINN', alpha=0.7, linewidth=1.5)\n",
        "    axes[0, 1].set_xlabel('Time (s)')\n",
        "    axes[0, 1].set_ylabel('COP_y (cm)')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].set_title(f'COP Y-direction (RMSE: {rmse_y:.3f}, RÂ²: {r2_y:.3f})')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # PLOT 3: Correlation Plot (True vs Predicted)\n",
        "    axes[0, 2].scatter(true_x, pred_x, alpha=0.5, s=10)\n",
        "    axes[0, 2].plot([true_x.min(), true_x.max()],\n",
        "                    [true_x.min(), true_x.max()], 'k--', alpha=0.7)\n",
        "    axes[0, 2].set_xlabel('True COP_x')\n",
        "    axes[0, 2].set_ylabel('Predicted COP_x')\n",
        "    axes[0, 2].set_title('Correlation COP_x')\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    # PLOT 4: COP Trajectory (Stabilogram)\n",
        "    axes[1, 0].plot(true_x, true_y, 'b-', label='True', alpha=0.7, linewidth=1)\n",
        "    axes[1, 0].plot(pred_x, pred_y, 'r--', label='PINN', alpha=0.7, linewidth=1)\n",
        "    axes[1, 0].set_xlabel('COP_x (cm)')\n",
        "    axes[1, 0].set_ylabel('COP_y (cm)')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].set_title('COP Trajectory (Stabilogram)')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    axes[1, 0].axis('equal')\n",
        "\n",
        "    # PLOT 5: Error Analysis\n",
        "    error_x = true_x - pred_x\n",
        "    error_y = true_y - pred_y\n",
        "    axes[1, 1].plot(time, error_x, 'g-', label='Error X', alpha=0.7, linewidth=1)\n",
        "    axes[1, 1].plot(time, error_y, 'm-', label='Error Y', alpha=0.7, linewidth=1)\n",
        "    axes[1, 1].axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
        "    axes[1, 1].set_xlabel('Time (s)')\n",
        "    axes[1, 1].set_ylabel('Error (cm)')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].set_title('Prediction Errors')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # PLOT 6: Frequency Domain Analysis\n",
        "    from scipy.fft import fft, fftfreq\n",
        "    N = len(true_x)\n",
        "    T = time[1] - time[0]\n",
        "    freqs = fftfreq(N, T)[:N//2]\n",
        "\n",
        "    fft_true_x = np.abs(fft(true_x))[:N//2]\n",
        "    fft_pred_x = np.abs(fft(pred_x))[:N//2]\n",
        "\n",
        "    axes[1, 2].plot(freqs[1:], fft_true_x[1:], 'b-', label='True X', alpha=0.7, linewidth=1)\n",
        "    axes[1, 2].plot(freqs[1:], fft_pred_x[1:], 'r--', label='PINN X', alpha=0.7, linewidth=1)\n",
        "    axes[1, 2].set_xlabel('Frequency (Hz)')\n",
        "    axes[1, 2].set_ylabel('Amplitude')\n",
        "    axes[1, 2].set_title('Frequency Spectrum (COP_x)')\n",
        "    axes[1, 2].legend()\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# REMAINING FUNCTIONS UNCHANGED\n",
        "# ============================================================================\n",
        "\n",
        "def plot_physics_parameter_evolution(damping_history, stiffness_history, record_name):\n",
        "    \"\"\"\n",
        "    Plots the evolution of learned damping and stiffness values over epochs.\n",
        "    \"\"\"\n",
        "    epochs = range(len(damping_history))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, damping_history, label='Learned Damping')\n",
        "    plt.plot(epochs, stiffness_history, label='Learned Stiffness')\n",
        "\n",
        "    # MODIFIED: Add physiological range indicators\n",
        "    plt.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Damping Range (1-20)')\n",
        "    plt.axhline(y=20.0, color='red', linestyle='--', alpha=0.5)\n",
        "    plt.axhline(y=10.0, color='blue', linestyle='--', alpha=0.5, label='Stiffness Range (10-500)')\n",
        "    plt.axhline(y=500.0, color='blue', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Parameter Value')\n",
        "    plt.title(f'Evolution of Learned Physics Parameters During Training ({record_name})')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "def run_balance_analysis(model, data_path):\n",
        "    \"\"\"Main function - UNCHANGED\"\"\"\n",
        "    print(\"=== SIMPLIFIED PINN BALANCE ANALYSIS ===\")\n",
        "\n",
        "    print(\"\\n1. Loading data...\")\n",
        "    time, cop_data, subject_info = load_balance_data(data_path)\n",
        "    print(f\"   Loaded {len(time)} data points\")\n",
        "    print(f\"   Subject: {subject_info['weight']:.1f} kg, {subject_info['height']:.2f} m\")\n",
        "\n",
        "    print(\"\\n2. Training PINN model...\")\n",
        "    model, loss_history, damping_history, stiffness_history = train_simple_pinn(model, time, cop_data, subject_info)\n",
        "\n",
        "    print(\"\\n3. Analyzing results...\")\n",
        "    analyze_results(model, time, cop_data, subject_info)\n",
        "\n",
        "    print(\"\\n4. Plotting physics parameter evolution...\")\n",
        "    record_name = os.path.basename(data_path)\n",
        "    plot_physics_parameter_evolution(damping_history, stiffness_history, record_name)\n",
        "\n",
        "    print(\"\\nAnalysis complete!\")\n",
        "    return model\n",
        "\n",
        "def analyze_multiple_files(folder_path, save_plots=True, results_folder=\"results\"):\n",
        "    \"\"\"Batch processing - UNCHANGED\"\"\"\n",
        "    if save_plots:\n",
        "        os.makedirs(results_folder, exist_ok=True)\n",
        "\n",
        "    dat_files = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith('.dat'):\n",
        "            record_name = file[:-4]\n",
        "            dat_files.append(os.path.join(folder_path, record_name))\n",
        "\n",
        "    print(f\"Found {len(dat_files)} WFDB records to process\")\n",
        "\n",
        "    model = SimpleBalancePINN()\n",
        "    print(\"\\nInitialized a single PINN model for batch processing.\")\n",
        "\n",
        "    for i, record_path in enumerate(dat_files):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Processing file {i+1}/{len(dat_files)}: {os.path.basename(record_path)}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        try:\n",
        "            model = run_balance_analysis(model, record_path)\n",
        "\n",
        "            if save_plots:\n",
        "                record_name = os.path.basename(record_path)\n",
        "                plot_filename = os.path.join(results_folder, f\"{record_name}_analysis.png\")\n",
        "                plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
        "                print(f\"Plot saved to: {plot_filename}\")\n",
        "\n",
        "                param_plot_filename = os.path.join(results_folder, f\"{record_name}_params_evolution.png\")\n",
        "                try:\n",
        "                     plt.savefig(param_plot_filename, dpi=300, bbox_inches='tight')\n",
        "                     print(f\"Parameter evolution plot saved to: {param_plot_filename}\")\n",
        "                except Exception as save_e:\n",
        "                    print(f\"Error saving parameter evolution plot for {os.path.basename(record_path)}: {save_e}\")\n",
        "\n",
        "            print(f\"âœ“ Successfully processed {os.path.basename(record_path)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âœ— Error processing {os.path.basename(record_path)}: {e}\")\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"All files processed!\")\n",
        "    if save_plots:\n",
        "        print(f\"Results saved to: {results_folder}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN LOOP - UNCHANGED\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_folder = \"/content/drive/MyDrive/human-balance-evaluation-database-1.0.0\"\n",
        "    analyze_multiple_files(data_folder)\n",
        "\n",
        "\"\"\"\n",
        "=== KEY MODIFICATIONS MADE TO FIX DAMPING ISSUE ===\n",
        "\n",
        "1. **Log Parameterization**:\n",
        "   - Changed from direct parameters to log_damping/log_stiffness\n",
        "   - Uses properties to ensure always positive values\n",
        "   - Better gradients during training\n",
        "\n",
        "2. **Parameter Regularization**:\n",
        "   - Added parameter_regularization_loss() function\n",
        "   - Keeps damping in 1-20 Nmâ‹…s/rad range\n",
        "   - Keeps stiffness in 10-500 Nm/rad range\n",
        "\n",
        "3. **Multi-Phase Training**:\n",
        "   - Gradually increases physics and regularization weights\n",
        "   - Prevents premature convergence to zero damping\n",
        "   - Better balance between fitting data and physics\n",
        "\n",
        "4. **Gradient Clipping**:\n",
        "   - Prevents training instability\n",
        "   - Helps maintain reasonable parameter values\n",
        "\n",
        "5. **Better Initialization**:\n",
        "   - Damping starts at 5.0 (reasonable value)\n",
        "   - Stiffness starts at 50.0 (reasonable value)\n",
        "\n",
        "6. **Validation Feedback**:\n",
        "   - Reports if parameters are in physiological ranges\n",
        "   - Shows reference lines in parameter evolution plots\n",
        "\n",
        "These minimal changes should prevent the damping from going to zero while\n",
        "keeping the same overall structure and functionality of your original code.\n",
        "\"\"\""
      ]
    }
  ]
}